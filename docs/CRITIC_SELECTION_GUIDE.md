# Sifaka Critic Selection Guide

This guide helps you choose the right critics for your text improvement needs.

## Quick Selection Matrix

| Task Type | Primary Critics | Secondary Critics | Why |
|-----------|----------------|-------------------|-----|
| **Academic Writing** | `self_consistency`, `constitutional` | `self_rag`, `meta_rewarding` | Ensures rigor, accuracy, and principle adherence |
| **Blog Posts** | `self_refine`, `n_critics` | `reflexion` | Focuses on engagement and multiple reader perspectives |
| **Technical Documentation** | `self_rag`, `constitutional` | `self_consistency` | Prioritizes accuracy and clarity |
| **Marketing Copy** | `n_critics`, `self_refine` | `constitutional` | Multiple perspectives and polished output |
| **Code Comments** | `constitutional`, `self_refine` | `reflexion` | Clear, helpful, and constructive |
| **Customer Communication** | `constitutional`, `n_critics` | `self_refine` | Respectful tone with stakeholder perspectives |
| **Creative Writing** | `reflexion`, `self_refine` | `meta_rewarding` | Iterative improvement with quality focus |
| **Fact-Heavy Content** | `self_rag`, `self_consistency` | `constitutional` | Verification and consensus on facts |
| **Legal/Compliance** | `constitutional`, `self_consistency` | `meta_rewarding` | Principle adherence with verification |
| **Educational Content** | `n_critics`, `self_refine` | `reflexion` | Multiple learning perspectives |

## Detailed Critic Profiles

### 1. **ReflexionCritic** ðŸ”„
**Best for:** Iterative improvement tasks where learning from previous attempts matters
- âœ… **Use when:** Content needs progressive refinement
- âœ… **Use when:** You have multiple iterations available
- âœ… **Use when:** Context from earlier attempts is valuable
- âŒ **Avoid when:** You need single-shot improvement
- âŒ **Avoid when:** Historical context isn't relevant
- **Speed:** Medium | **Cost:** Medium | **Iterations:** 3-5 optimal

### 2. **ConstitutionalCritic** ðŸ“‹
**Best for:** Ensuring content adheres to principles and guidelines
- âœ… **Use when:** Safety and accuracy are paramount
- âœ… **Use when:** You have specific principles to follow
- âœ… **Use when:** Ethical considerations matter
- âŒ **Avoid when:** Creative freedom is priority
- âŒ **Avoid when:** Principles might constrain innovation
- **Speed:** Fast | **Cost:** Low | **Iterations:** 1-2 usually sufficient

### 3. **SelfRefineCritic** âœ¨
**Best for:** General quality improvement across multiple dimensions
- âœ… **Use when:** You want well-rounded improvements
- âœ… **Use when:** No specific constraints exist
- âœ… **Use when:** Polish and flow matter
- âŒ **Avoid when:** You need specialized expertise
- âŒ **Avoid when:** Fact-checking is critical
- **Speed:** Fast | **Cost:** Low | **Iterations:** 2-3 optimal

### 4. **NCriticsCritic** ðŸ‘¥
**Best for:** Getting diverse perspectives on content
- âœ… **Use when:** Multiple stakeholder views matter
- âœ… **Use when:** You're unsure what to improve
- âœ… **Use when:** Comprehensive feedback needed
- âŒ **Avoid when:** You need focused, specific feedback
- âŒ **Avoid when:** Speed is critical
- **Speed:** Slower | **Cost:** Higher | **Iterations:** 1-2 comprehensive

### 5. **SelfRAGCritic** ðŸ”
**Best for:** Content requiring factual accuracy and verification
- âœ… **Use when:** Facts and claims need verification
- âœ… **Use when:** Citations would improve credibility
- âœ… **Use when:** Technical accuracy matters
- âŒ **Avoid when:** Content is opinion-based
- âŒ **Avoid when:** Creative expression is key
- **Speed:** Medium | **Cost:** Medium (Higher with retrieval) | **Iterations:** 1-2

### 6. **MetaRewardingCritic** ðŸŽ¯
**Best for:** High-stakes content needing quality assurance
- âœ… **Use when:** Critique quality itself matters
- âœ… **Use when:** You need confidence in feedback
- âœ… **Use when:** Self-evaluation is valuable
- âŒ **Avoid when:** Quick feedback needed
- âŒ **Avoid when:** Simple improvements suffice
- **Speed:** Slower | **Cost:** Higher | **Iterations:** 1-2 deep

### 7. **SelfConsistencyCritic** ðŸŽ²
**Best for:** Achieving consensus through multiple evaluations
- âœ… **Use when:** Consistency matters more than speed
- âœ… **Use when:** You want robust, reliable feedback
- âœ… **Use when:** Variance in critique is concerning
- âŒ **Avoid when:** Deterministic feedback needed
- âŒ **Avoid when:** Budget is tight
- **Speed:** Slowest | **Cost:** Highest (3x normal) | **Iterations:** 1 (but 3 internal)

### 8. **PromptCritic** ðŸ› ï¸
**Best for:** Custom evaluation criteria and experiments
- âœ… **Use when:** You have specific requirements
- âœ… **Use when:** Existing critics don't fit
- âœ… **Use when:** Experimenting with new approaches
- âŒ **Avoid when:** Standard critics suffice
- âŒ **Avoid when:** You want proven approaches
- **Speed:** Variable | **Cost:** Low | **Iterations:** Variable

## Effective Critic Combinations

### For Maximum Quality
```python
critics = ["self_consistency", "constitutional", "meta_rewarding"]
```
**Why:** Consensus + principles + quality verification

### For Fast Improvement
```python
critics = ["self_refine", "constitutional"]
```
**Why:** Quick general improvements with safety checks

### For Technical Content
```python
critics = ["self_rag", "self_consistency", "n_critics"]
```
**Why:** Fact-checking + consensus + expert perspectives

### For Creative Content
```python
critics = ["reflexion", "self_refine", "prompt:creative_writing"]
```
**Why:** Iterative learning + polish + custom creative criteria

### For User-Facing Content
```python
critics = ["constitutional", "n_critics", "self_refine"]
```
**Why:** Safe + multiple perspectives + polished

## Performance Considerations

### Speed Ranking (Fastest to Slowest)
1. **constitutional** - Single evaluation, principle-based
2. **self_refine** - Single evaluation, structured
3. **prompt** - Single evaluation, custom
4. **reflexion** - Depends on history depth
5. **self_rag** - Fact identification overhead
6. **meta_rewarding** - Two-stage process
7. **n_critics** - Multiple perspectives
8. **self_consistency** - Multiple evaluations (3x)

### Cost Efficiency
- **Most Efficient:** `constitutional`, `self_refine`
- **Moderate:** `reflexion`, `self_rag`, `prompt`
- **Higher Cost:** `meta_rewarding`, `n_critics`
- **Highest Cost:** `self_consistency` (3x tokens)

### Iteration Patterns
- **Single iteration often enough:** `constitutional`, `self_consistency`
- **2-3 iterations optimal:** `self_refine`, `self_rag`
- **3-5 iterations beneficial:** `reflexion`
- **1-2 deep iterations:** `meta_rewarding`, `n_critics`

## Decision Tree

```
Start: What's your primary goal?
â”‚
â”œâ”€> Accuracy/Facts Critical?
â”‚   â”œâ”€> Yes: Use self_rag
â”‚   â”‚   â””â”€> Add self_consistency for consensus
â”‚   â””â”€> No: Continue
â”‚
â”œâ”€> Multiple Stakeholders?
â”‚   â”œâ”€> Yes: Use n_critics
â”‚   â”‚   â””â”€> Add constitutional for safety
â”‚   â””â”€> No: Continue
â”‚
â”œâ”€> Iterative Improvement Needed?
â”‚   â”œâ”€> Yes: Use reflexion
â”‚   â”‚   â””â”€> Add self_refine for polish
â”‚   â””â”€> No: Continue
â”‚
â”œâ”€> Specific Principles/Rules?
â”‚   â”œâ”€> Yes: Use constitutional
â”‚   â”‚   â””â”€> Add meta_rewarding for verification
â”‚   â””â”€> No: Use self_refine
â”‚
â””â”€> Custom Requirements?
    â””â”€> Yes: Use prompt with custom criteria
```

## Common Patterns by Industry

### Academia/Research
```python
critics = ["self_rag", "self_consistency", "constitutional"]
config = Config(temperature=0.3, max_iterations=3)
```

### Marketing/Sales
```python
critics = ["n_critics", "self_refine", "constitutional"]
config = Config(temperature=0.7, max_iterations=2)
```

### Technical Writing
```python
critics = ["self_rag", "constitutional", "self_refine"]
config = Config(temperature=0.4, max_iterations=2)
```

### Creative Writing
```python
critics = ["reflexion", "self_refine", "meta_rewarding"]
config = Config(temperature=0.8, max_iterations=4)
```

### Customer Service
```python
critics = ["constitutional", "n_critics"]
config = Config(temperature=0.5, max_iterations=2)
```

## Tips for Best Results

1. **Start Simple**: Begin with 1-2 critics and add more if needed
2. **Order Matters**: Place fact-checking critics early, polish critics later
3. **Monitor Costs**: Self-consistency is 3x more expensive
4. **Use Validators**: Combine critics with validators for constraints
5. **Configure Temperature**: Lower for formal, higher for creative
6. **Set Iteration Limits**: Most improvements happen in first 2-3 iterations

## Future Considerations

As you use Sifaka, consider:
- Tracking which critics work best for your use cases
- Creating custom prompt critics for repeated patterns
- Building retrieval backends for SelfRAG if accuracy is critical
- Monitoring performance metrics to optimize selection

Remember: The best critic combination depends on your specific context, constraints, and quality requirements. Start with the recommendations above and adjust based on results.
