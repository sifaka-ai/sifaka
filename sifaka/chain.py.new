"""
Chain orchestration for Sifaka.

This module defines the Chain class, which is the main entry point for the Sifaka framework.
It orchestrates the generation, validation, and improvement of text using LLMs.

The Chain class uses a builder pattern to provide a fluent API for configuring and
executing LLM operations. It allows you to specify which model to use, set the prompt
for generation, add validators to check if the generated text meets requirements,
add improvers to enhance the quality of the generated text, and configure model options.

Example:
    ```python
    from sifaka import Chain
    from sifaka.validators import length
    from sifaka.critics import create_lac_critic

    result = (Chain()
        .with_model("openai:gpt-4")
        .with_prompt("Write a short story about a robot.")
        .validate_with(length(min_words=50, max_words=200))
        .improve_with(create_lac_critic("openai:gpt-4"))
        .run())

    print(f"Result passed validation: {result.passed}")
    print(result.text)
    ```
"""

from typing import Union, List, Dict, Any, Optional, Callable

from sifaka.interfaces import Model, Validator, Improver
from sifaka.factories import (
    create_model_from_string,
    parse_model_string,
    FactoryError,
)


class ChainError(Exception):
    """Error raised when a chain operation fails."""
    pass


class ChainResult:
    """Result of a chain execution.
    
    Attributes:
        text: The final text after all validations and improvements.
        passed: Whether all validations passed.
        validation_results: Results of all validations.
        improvement_results: Results of all improvements.
    """
    
    def __init__(
        self,
        text: str,
        passed: bool,
        validation_results: List[Any],
        improvement_results: List[Any],
    ):
        """Initialize a chain result.
        
        Args:
            text: The final text after all validations and improvements.
            passed: Whether all validations passed.
            validation_results: Results of all validations.
            improvement_results: Results of all improvements.
        """
        self.text = text
        self.passed = passed
        self.validation_results = validation_results
        self.improvement_results = improvement_results


class Chain:
    """Main orchestrator for the generation, validation, and improvement flow.

    The Chain class is the central component of Sifaka. It coordinates the process of:
    1. Generating text using a language model
    2. Validating the generated text against specified criteria
    3. Improving the text using various improvement strategies

    The class uses a builder pattern to provide a fluent API, allowing method chaining
    for a more readable and intuitive interface.

    Attributes:
        _model: The model to use for generation.
        _prompt: The prompt to use for generation.
        _validators: List of validators to apply to the generated text.
        _improvers: List of improvers to apply to the generated text.
        _options: Options to pass to the model during generation.
        _model_factory: Factory function for creating models.
    """

    def __init__(
        self,
        model_factory: Optional[Callable[[str, str], Model]] = None,
    ):
        """Initialize a new Chain instance.

        Args:
            model_factory: Optional factory function for creating models.
                If not provided, the default factory function will be used.
                The factory function should take a provider and model name and return a Model instance.
        """
        self._model: Optional[Model] = None
        self._prompt: Optional[str] = None
        self._validators: List[Validator] = []
        self._improvers: List[Improver] = []
        self._options: Dict[str, Any] = {}
        
        # Use the provided model factory or the default
        self._model_factory = model_factory or create_model_from_string

    def with_model(self, model: Union[str, Model]) -> "Chain":
        """Set the model to use for generation.

        This method configures the model that will be used to generate text when the chain
        is run. You can provide either a model instance or a string in the format
        "provider:model_name", which will be used to create a model instance.

        Args:
            model: Either a model instance or a string in the format "provider:model_name".
                  Supported providers include "openai", "anthropic", "gemini", and "mock".

        Returns:
            The chain instance for method chaining.

        Examples:
            ```python
            # Using a string
            chain = Chain().with_model("openai:gpt-4")

            # Using a model instance
            from sifaka.models import OpenAIModel
            model = OpenAIModel("gpt-4", api_key="your-api-key")
            chain = Chain().with_model(model)
            ```

        Raises:
            ChainError: If the model string is invalid or the model cannot be created.
        """
        if isinstance(model, str):
            try:
                # Create a model from the string
                self._model = self._model_factory(model)
            except (ValueError, FactoryError) as e:
                raise ChainError(f"Error creating model: {str(e)}") from e
        else:
            # Use the provided model instance
            self._model = model
        return self

    def with_prompt(self, prompt: str) -> "Chain":
        """Set the prompt to use for generation.

        Args:
            prompt: The prompt to use for generation.

        Returns:
            The chain instance for method chaining.
        """
        self._prompt = prompt
        return self

    def validate_with(self, validator: Validator) -> "Chain":
        """Add a validator to the chain.

        Args:
            validator: The validator to add.

        Returns:
            The chain instance for method chaining.
        """
        self._validators.append(validator)
        return self

    def improve_with(self, improver: Improver) -> "Chain":
        """Add an improver to the chain.

        Args:
            improver: The improver to add.

        Returns:
            The chain instance for method chaining.
        """
        self._improvers.append(improver)
        return self

    def with_options(self, **options: Any) -> "Chain":
        """Set options for the model.

        Args:
            **options: Options to pass to the model.

        Returns:
            The chain instance for method chaining.
        """
        self._options.update(options)
        return self

    def run(self) -> ChainResult:
        """Execute the chain and return the result.

        This method runs the complete chain execution process:
        1. Checks that the chain is properly configured (has a model and prompt)
        2. Generates text using the model and prompt
        3. Validates the generated text using all configured validators
        4. If all validations pass, improves the text using all configured improvers
        5. Returns a ChainResult object containing the final text and all validation/improvement results

        The validation process stops at the first validator that fails, returning a failed result.
        Improvers are applied in sequence, with each improver receiving the text from the previous one.

        Returns:
            The result of the chain execution, containing:
            - The final text after all validations and improvements
            - Whether all validations passed
            - The results of all validations
            - The results of all improvements

        Raises:
            ChainError: If the chain is not properly configured (missing model or prompt).

        Example:
            ```python
            from sifaka import Chain
            from sifaka.validators import length
            from sifaka.critics import create_lac_critic

            result = (Chain()
                .with_model("openai:gpt-4")
                .with_prompt("Write a short story about a robot.")
                .validate_with(length(min_words=50, max_words=200))
                .improve_with(create_lac_critic("openai:gpt-4"))
                .run())

            if result.passed:
                print("Chain execution succeeded")
                print(result.text)
            else:
                print("Chain execution failed validation")
                print(result.validation_results[0].message)
            ```
        """
        if not self._model:
            raise ChainError("Model not specified")
        if not self._prompt:
            raise ChainError("Prompt not specified")

        # Generate initial text
        try:
            text = self._model.generate(self._prompt, **self._options)
        except Exception as e:
            raise ChainError(f"Error generating text: {str(e)}") from e

        # Validate text
        validation_results = []
        for validator in self._validators:
            try:
                result = validator.validate(text)
                validation_results.append(result)
                if not result.passed:
                    return ChainResult(
                        text=text,
                        passed=False,
                        validation_results=validation_results,
                        improvement_results=[],
                    )
            except Exception as e:
                raise ChainError(f"Error validating text: {str(e)}") from e

        # Improve text
        improvement_results = []
        for improver in self._improvers:
            try:
                improved_text, result = improver.improve(text)
                improvement_results.append(result)
                text = improved_text
            except Exception as e:
                raise ChainError(f"Error improving text: {str(e)}") from e

        return ChainResult(
            text=text,
            passed=True,
            validation_results=validation_results,
            improvement_results=improvement_results,
        )
